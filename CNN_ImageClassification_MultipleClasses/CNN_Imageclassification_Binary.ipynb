{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a716b8a",
   "metadata": {},
   "source": [
    "# Data Path https://data.caltech.edu/records/mzrjq-6wc02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0b1e18",
   "metadata": {},
   "source": [
    "#  Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f96b2af-1d2e-4fd2-8c9f-2e8cad495b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "315c6647-9efb-4bba-b1c7-cd31c65df041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548d9201",
   "metadata": {},
   "source": [
    "# Initialising the CNN with 2 convolutional layers, filters, feature maps, fullyconnected layer, maxpooling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a7ee36-5187-47e2-aeb4-19867516b3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (256, 256, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af090db",
   "metadata": {},
   "source": [
    "# Importing ImageDataGenerator which helps us to normalize the data by bringing the data into range(0,1),setting batch size, target_size and requidred class_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6db028ad-f0a9-40a6-be03-e39fcce16537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59dea476-d43c-47fd-8f5a-e70038dfdfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(r'D:\\QTInternship\\caltech-101\\caltech-101\\training_data_binary',\n",
    "                                                 target_size = (256, 256),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6c3fff3-1760-475c-9473-97bad4807dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory(r'D:\\QTInternship\\caltech-101\\caltech-101\\testing_data_binary',\n",
    "                                            target_size = (256, 256),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2ac602",
   "metadata": {},
   "source": [
    "# Fitting the model by specifying epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5db8a4ef-06fd-414c-bad1-ed0e034f4e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2/2 [==============================] - 2s 679ms/step - loss: 1.1877 - accuracy: 0.5556 - val_loss: 0.7551 - val_accuracy: 0.5897\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.1979 - accuracy: 0.5000 - val_loss: 2.4088 - val_accuracy: 0.4103\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.6532 - accuracy: 0.6111 - val_loss: 1.9487 - val_accuracy: 0.5897\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.5199 - accuracy: 0.8333 - val_loss: 0.5150 - val_accuracy: 0.7179\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 2s 474ms/step - loss: 0.2149 - accuracy: 0.9167 - val_loss: 0.5524 - val_accuracy: 0.5897\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 2s 459ms/step - loss: 0.2954 - accuracy: 0.8611 - val_loss: 0.3271 - val_accuracy: 0.9487\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 2s 461ms/step - loss: 0.1940 - accuracy: 0.9444 - val_loss: 0.3434 - val_accuracy: 0.8462\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.1827 - accuracy: 0.9722 - val_loss: 0.2296 - val_accuracy: 0.9487\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 2s 477ms/step - loss: 0.1432 - accuracy: 0.9722 - val_loss: 0.2194 - val_accuracy: 0.9231\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - 2s 479ms/step - loss: 0.1027 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9487\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 2s 531ms/step - loss: 0.1034 - accuracy: 0.9722 - val_loss: 0.2940 - val_accuracy: 0.8462\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 2s 2s/step - loss: 0.1294 - accuracy: 0.9167 - val_loss: 0.1769 - val_accuracy: 0.9231\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0443 - accuracy: 0.9722 - val_loss: 0.2058 - val_accuracy: 0.9744\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 2s 542ms/step - loss: 0.1467 - accuracy: 0.9444 - val_loss: 0.2113 - val_accuracy: 0.9231\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 2s 470ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.3570 - val_accuracy: 0.8205\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - 2s 510ms/step - loss: 0.0672 - accuracy: 0.9722 - val_loss: 0.2126 - val_accuracy: 0.9231\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 2s 491ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.9487\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 2s 491ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9487\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0500 - accuracy: 0.9722 - val_loss: 0.2841 - val_accuracy: 0.9487\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 2s 518ms/step - loss: 0.1024 - accuracy: 0.9722 - val_loss: 0.1499 - val_accuracy: 0.9487\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 2s 514ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9231\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - 2s 508ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.3294 - val_accuracy: 0.8718\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9231\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 2s 536ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9487\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - 2s 520ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.1590 - val_accuracy: 0.9231\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9231\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 2s 479ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.8718\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - 2s 501ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.3038 - val_accuracy: 0.8974\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9231\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 2s 535ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 0.9487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x286748d7fd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(training_set,\n",
    "                         epochs = 30,\n",
    "                         validation_data = test_set\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff6c334",
   "metadata": {},
   "source": [
    "# Checking the model summary to see model structure, total params,trainable params, non trainable params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cbe0aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 123008)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               15745152  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,755,425\n",
      "Trainable params: 15,755,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f84fcd",
   "metadata": {},
   "source": [
    "# Testing our models performance by selecting specific images. Importing image from tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0afff5d4-eeb0-46f6-a55d-8cdcab9eebdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 127ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "#from keras.preprocessing import image\n",
    "test_image = image.load_img('D:/QTInternship/caltech-101/caltech-101/101_ObjectCategories/airplanes/image_0614.jpg'\n",
    "                   , target_size=(256, 256))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = classifier.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56061abf-ef38-4131-bf95-71244cb92209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30aacd67-0064-4a3b-a030-806b6e5a2e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "test_image =image.load_img('D:/QTInternship/caltech-101/caltech-101/101_ObjectCategories/car_side/image_0030.jpg'\n",
    "                   , target_size=(256, 256))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = classifier.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3974e5ff-a483-4fbf-8e82-7c7dd271c1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
